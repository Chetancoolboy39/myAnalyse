You are an expert full-stack enterprise architect. Build a **complete production-ready system** called **JIRA Standardization Tool** with:

ğŸ’  Streamlit UI  
ğŸ’  Python Backend (FastAPI)  
ğŸ’  Jira REST API Integration  
ğŸ’  LLM REST API Integration for rewriting + acceptance criteria

---

## ğŸ¯ System Objective
Users will enter Jira ticket content via a professional UX-friendly Streamlit UI.  
The backend will call an internal LLM REST API to rewrite content in a **standardized, technical, structured Jira format**.  
Users must preview **Before vs After**, then click **Create Jira** to generate the ticket via Jira REST API.

---

## ğŸ”¹ STREAMLIT UI REQUIREMENTS (MUST FOLLOW)
Required fields (all are mandatory):
- Project (dropdown populated from backend `/projects`)
- Title
- Functional Requirement
- Current Behavior
- Expected Behavior
- BA Analysis

â— Acceptance Criteria **MUST NOT** be asked from the user.  
It will be generated automatically from **Expected Behavior** by LLM.

### UI Flow
1. User fills all inputs
2. Clicks **â€œFormat with AIâ€**
3. Show **side-by-side Before vs After comparison**
4. Add **visual highlighting of changed words/phrases** (if simple implementation possible)
5. Ask user to **Approve**
6. After approval â†’ call **backend `/create-jira`** to create the Jira ticket
7. Display success message with Jira URL

### UI Design Requirements
- Clean & professional layout
- Responsive in desktop + widescreen
- Loading animation while formatting & creating Jira
- Clear error messages
- Download button to export formatted text (optional but preferred)

---

## ğŸ”¹ BACKEND REQUIREMENTS (FASTAPI)
Implement the following endpoints:

| Endpoint | Purpose |
|---------|---------|
| `GET /projects` | Fetch Jira project list |
| `POST /format` | Send user inputs to LLM API â†’ rewrite & return formatted payload |
| `POST /create-jira` | Create Jira issue with final approved formatted content |

### Backend Obligations
- Central `config.py` for environment variables
- Logging + error handling + validation
- Timeout + retry for LLM & Jira API calls
- Type hints, docstrings, PEP8

---

## ğŸ”¹ JIRA PAYLOAD FORMAT
Use HTML Wiki formatting:

```
h2. Functional Requirement
<content>

h2. Current Behavior
<content>

h2. Expected Behavior
<content>

h2. BA Analysis
<content>

h2. Acceptance Criteria
<gherkin style generated by LLM>
```

### Issue Type
- Story (default)

---

## ğŸ”¹ LLM PROMPT FORMAT TO USE INTERNALLY
The backend must send the following prompt when calling the LLM:

```
Rewrite the input in a professional and technical Jira ticket style.
Keep structure strict and remove storytelling tone.

Acceptance Criteria:
Derive acceptance criteria from Expected Behavior.
Format using Gherkin:
Given <context>
When <action>
Then <expected outcome>
```

---

## ğŸ”¹ PLACEHOLDER FOR SAMPLE LLM CODE  ğŸ”¥ (MANDATORY)
Create a file:
```
/backend/llm_sample_code.py
```
Inside it include:

```python
"""
This file is intentionally kept as a placeholder for custom LLM logic.
We will later paste sample internal LLM code here.
Call format_llm_payload(payload) from main code once sample logic is added.
"""
def format_llm_payload(payload: dict) -> dict:
    raise NotImplementedError("LLM code not added yet")
```

and ensure backend has TODO markers where this module will be plugged in.

---

## ğŸ”¹ DELIVERABLES
Generate everything in this order automatically:

1ï¸âƒ£ Full folder structure  
2ï¸âƒ£ Backend (FastAPI) â€” complete working code  
3ï¸âƒ£ Streamlit UI â€” complete working code  
4ï¸âƒ£ Environment variables + config design  
5ï¸âƒ£ requirements.txt  
6ï¸âƒ£ README.md â€” detailed setup + run instructions  
7ï¸âƒ£ Unit tests for backend  
8ï¸âƒ£ Postman collection (JSON)  
9ï¸âƒ£ Sample screenshots using ASCII preview  
ğŸ”Ÿ Local run command (`uvicorn` + `streamlit run`)

---

## ğŸ”¹ DEVELOPMENT STANDARDS
- No hardcoded secrets â†’ `.env`
- Clean naming conventions
- Comments everywhere Copilot might need context
- Scalable for future multi-project Jira deployment
- Code must run without manual fixes

ğŸ’¥ Start building the full production-grade system now. First, generate the folder structure, then implement modules step-by-step automatically.
